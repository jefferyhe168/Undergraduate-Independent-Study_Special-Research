{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keyword-extractor_ver2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI10r1LnA-C1",
        "outputId": "1ad9e929-ad0b-47c6-b878-b27ab35f740d"
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install PyMuPDF"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.18.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.7 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.21.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.7->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.7->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.7->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.18.15-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 21.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk3OOE7U0ZAz"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import fitz # pymupdf(讀pdf的套件)\n",
        "import re #用以同時刪除多種不同字元"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Usz8XOBILo"
      },
      "source": [
        "# 讀pdf\n",
        "pdf_document = \"testing.pdf\"\n",
        "doc = fitz.open(pdf_document)\n",
        "pdf_text = \"\"\n",
        "\n",
        "for i in range(0,doc.pageCount): #一頁一頁讀\n",
        "    page = doc.loadPage(i) #讀第i頁的文字\n",
        "    pagetext = page.getText(\"text\")\n",
        "    pdf_text += re.sub('[\\n]', '', pagetext) #去除換行符號\n",
        "\n",
        "# print(\"pdf text: \",pdf_text)\n",
        "text_list = re.split('\\.',pdf_text) # 使用\".\"來分隔文字\n",
        "#以句號為標準來判斷做句子分割(解決小數點問題)\n",
        "for i in range(len(text_list)):\n",
        "    if(i!=0 and i<len(text_list)):\n",
        "        # print('text_list content:',text_list[i]) # self testing\n",
        "        # 若分割後的句子「最後一個字元為數字，且下一句的第一個字元亦為數字」，表示這兩句之間的”.”是小數點而非句號\n",
        "        if( text_list[i-1][-1].isdigit() and text_list[i][0].isdigit() ):\n",
        "            # print('i=',i) # self testing\n",
        "            # 將兩句合併回一個句子\n",
        "            text_list[i-1] = text_list[i-1] + \".\" + text_list[i]\n",
        "            del text_list[i]\n",
        "\n",
        "# 用filter過濾掉text_list中句子長度小於等於6的句子\n",
        "sentence_list = list(filter(lambda x: len(x) > 6, text_list))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a68sSjQAxX5",
        "outputId": "c01a49fb-2a26-4564-89a7-929b24376431"
      },
      "source": [
        "# 使用GPU環境\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tag2idx = {'B': 0, 'I': 1, 'O': 2}\n",
        "tags_vals = ['B', 'I', 'O']\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))\n",
        "\n",
        "def keywordextract(sentence, path):\n",
        "    text = sentence\n",
        "    tkns = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n",
        "    segments_ids = [0] * len(tkns)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "    model = torch.load(path)\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    logit = model(tokens_tensor, token_type_ids=None, attention_mask=segments_tensors)\n",
        "    logit = logit.detach().cpu().numpy()\n",
        "    prediction.extend([list(p) for p in np.argmax(logit, axis=2)])\n",
        "    for k, j in enumerate(prediction[0]):\n",
        "        if j==1 or j==0:\n",
        "            print(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k], j)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 10803699.80B/s]\n",
            "100%|██████████| 407873900/407873900 [00:08<00:00, 48181566.48B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrqlvJgNA8Fw",
        "outputId": "1f605018-94a8-4a3e-e79e-aa1e01ee8363"
      },
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "# 以一個句子為單位將文章一句一句輸入\n",
        "for i in range(len(sentence_list)):\n",
        "    print(\"sentence\",i+1,\"keyword:\")\n",
        "    parser = argparse.ArgumentParser(description='BERT Keyword Extractor')\n",
        "\n",
        "    parser.add_argument('--sentence', type=str, default= sentence_list[i] , help='sentence to get keywords')\n",
        "\n",
        "    parser.add_argument('--path', type=str, default='/content/drive/MyDrive/model.pt',help='path to load model')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    keywordextract(args.sentence, args.path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence 1 keyword:\n",
            "language 0\n",
            "processing 1\n",
            "sentence 2 keyword:\n",
            "language 0\n",
            "sentence 3 keyword:\n",
            "the 0\n",
            "language 1\n",
            "sentence 4 keyword:\n",
            "language 0\n",
            "model 1\n",
            "sentence 5 keyword:\n",
            "sentence 6 keyword:\n",
            "text 0\n",
            "sentence 7 keyword:\n",
            "language 0\n",
            "processing 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}